{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dr8b\n",
    "\n",
    "The goal of this notebook is to document how we ran [dr8b](https://desi.lbl.gov/trac/wiki/DecamLegacy/DR8#Testregions), including calibration files, with the updated data model and using the burst buffer + Docker image on Cori.\n",
    "\n",
    "John Moustakas  \n",
    "Siena College  \n",
    "2019 March\n",
    "\n",
    "Many thanks to Dustin Lang, Adam Myers, Eddie Schlafly, David Schlegel, Martin Landriau, and Stephen Bailey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1. Define $LEGACY_SURVEY_DIR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, choose a new, empty top-level working directory on `project` and create it:\n",
    "```bash\n",
    "mkdir -p /global/project/projectdirs/cosmo/work/legacysurvey/dr8b\n",
    "cd /global/project/projectdirs/cosmo/work/legacysurvey/dr8b\n",
    "```\n",
    "**Hereafter I will assume that all scripts are launched from this working directory, unless otherwise specified (starting in Section C).**\n",
    "\n",
    "Next, create soft links to the CP-reduced imaging data and the WISE background models:\n",
    "```bash\n",
    "mkdir -p images calib/wise\n",
    "ln -s /global/project/projectdirs/cosmo/staging/90prime images/90prime\n",
    "ln -s /global/project/projectdirs/cosmo/staging/mosaic images/mosaic\n",
    "ln -s /global/project/projectdirs/cosmo/staging/decam images/decam\n",
    "ln -s /project/projectdirs/cosmo/work/wise/unwise_catalog/dr1/mod calib/wise/modelsky\n",
    "```\n",
    "\n",
    "And finally grab a copy of the DR-independent `survey-bricks` file, which we will need below:\n",
    "```bash\n",
    "cp /global/project/projectdirs/cosmo/work/legacysurvey/dr7/survey-bricks.fits.gz .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Access (or create) the burst buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, Dustin Lang created a 40TB burst-buffer reservation called \"DR8\".  You can think of this as a mounted external drive, where large files can be written and read without the significant overhead associated with `$SCRATCH`, although eventually the results will be copied onto `project`, as described below.\n",
    "\n",
    "To access this file system for the first time you have to create a configuration file (just once).\n",
    "```bash\n",
    "echo \"#DW persistentdw name=DR8\" > bb.conf\n",
    "```\n",
    "\n",
    "The files in the burst buffer can be accessed *only* from an interactive Cori node.  Let's do this (just once) and make a dedicated subdirectory to keep our outputs tidy:\n",
    "```bash\n",
    "salloc -N 1 -C haswell -q interactive -t 00:10:00 --bbf=bb.conf\n",
    "mkdir -p $DW_PERSISTENT_STRIPED_DR8/dr8b\n",
    "```\n",
    "Note that the `$DW_PERSISTENT_STRIPED_DR8` environment variable must be used *always*, as every user will have a different absolute path.\n",
    "\n",
    "For the record, a new reservation can be made (if necessary) by submitting the following SLURM script to the queue:\n",
    "\n",
    "```bash\n",
    "#! /bin/bash\n",
    "#SBATCH -q debug\n",
    "#SBATCH -N 1\n",
    "#SBATCH -C haswell\n",
    "#SBATCH -t 00:05:00\n",
    "#BB create_persistent name=BBNAME capacity=50000GB access_mode=striped type=scratch\n",
    "```\n",
    "where `BBNAME` is the desired name of the reservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Set up software dependencies.\n",
    "**ToDo**: Add instructions for compiling tractor and astrometry.net, if needed (separate notebook).  \n",
    "**Note**: In `dr8b` we had to rely on a local installations of `tractor` and `astrometry.net` (especially on edison), but here we document the ideal setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure your environment is clean!  In other words, ensure that you don't explicitly load any modules or source any code in your initialization files (e.g., `$HOME/.bash_profile.ext` or `$HOME/.bashrc.ext`).\n",
    "\n",
    "Most of the code dependencies we need are in the `Docker` container, including [tractor](https://github.com/dstndstn/tractor) and [astrometry.net](https://github.com/dstndstn/astrometry.net), described below, but we usually depend on a recent (hopefully tagged) version of [legacyzpts](https://github.com/legacysurvey/legacyzpts), [legacypipe](https://github.com/legacysurvey/legacypipe), and [qdo](https://bitbucket.org/berkeleylab/qdo.git).  To keep everything tidy, check out the code into a dedicated directory, although note some of the shell scripts below *assume* this directory!\n",
    "\n",
    "```bash\n",
    "mkdir -p code ; cd code\n",
    "git clone git@github.com:legacysurvey/legacyzpts.git\n",
    "git clone git@github.com:legacysurvey/legacypipe.git\n",
    "git clone https://bitbucket.org/berkeleylab/qdo.git\n",
    "```\n",
    "**Be sure to check out the appropriate branches of these software packages as necessary.**\n",
    "\n",
    "Next, pull the latest `Docker` container\n",
    "```bash\n",
    "shifterimg pull docker:legacysurvey/legacypipe:latest\n",
    "```\n",
    "which one can enter (if desired) with the command\n",
    "```bash\n",
    "shifter --image docker:legacysurvey/legacypipe:latest bash\n",
    "```\n",
    "\n",
    "Although we use the `Docker` container for production, for a lot of preparatory work and debugging it's often convenient to load all the software dependencies and myriad environment variables on the command line, outside of the `Docker` container.  We provide a simple shell script for this purpose in `legacypipe` which we recommend copying to the local working directory for convenience of editing, temporarily changing paths, etc.:\n",
    "```bash\n",
    "cp code/legacypipe/doc/dr8/dr8-env.sh ./\n",
    "source dr8-env.sh\n",
    "```\n",
    "**This shell script has a single environment variable, `$CODE_DIR` for pointing to the locally checked out code, which should be updated as necessary.**\n",
    "\n",
    "Finally, you will also need to add the following lines (and get the appropriate database password) in order to complete the `qdo` setup (for the *desiconda* user these lines are in the `.bashrc.ext` file):\n",
    "```bash\n",
    "export QDO_BACKEND=postgres\n",
    "export QDO_BATCH_PROFILE=cori\n",
    "export QDO_DB_HOST=nerscdb03.nersc.gov\n",
    "export QDO_DB_NAME=desirun\n",
    "export QDO_DB_USER=desirun_admin\n",
    "export QDO_DB_PASS=XXXXXXXX\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. Create the input image lists.\n",
    "* **ToDo**: Update to the final flat-files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DR8 Eddie Schlafly and David Schlegel inspected all the `DECam`, `90prime`, and `mosaic` imaging data on-disk and created three FITS files which should be used to define the input data:\n",
    "* dr8-ondisk-decam.fits\n",
    "* dr8-ondisk-90prime.fits\n",
    "* dr8-ondisk-mosaic.fits\n",
    "\n",
    "We use these tables (cutting on `QKEEP==True`) to create our input image lists.  To keep everything tidy, create a new `image-lists` subdirectory, copy (**ToDo: specify location**) the `dr8-ondisk-*.fits` files there, source the `dr8-env.sh` file, and then run the following snippet of code in an `ipython` session.\n",
    "```python\n",
    "import os\n",
    "import fitsio\n",
    "for camera in ('decam', 'mosaic', '90prime'):\n",
    "    data = fitsio.read('dr8-ondisk-{}.fits'.format(camera), upper=True)\n",
    "    with open('image-list-{}.txt'.format(camera), 'w') as flist:\n",
    "        for imfile in data[data['QKEEP']]['FILENAME']:\n",
    "            flist.write('{}\\n'.format(os.path.join(camera, imfile.decode('utf-8').strip())))\n",
    "```\n",
    "The resulting output files are:\n",
    "* image-list-decam.txt (121123 images in DR8, 5515 in DR8b)\n",
    "* image-list-90prime.txt (34206 images in DR8, 1073 in DR8b)\n",
    "* image-list-mosaic.txt (61049 images in DR8, 1374 in DR8b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Generate the calibration files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Load and launch qdo tasks (lists of images).\n",
    "\n",
    "We use `qdo` to manage the myriad of tasks (one task = one image), and the `shifter` script `dr8-zpts-shifter.sh` to produce the calibration files we need.  First, load the tasks into the database with\n",
    "```bash\n",
    "qdo load dr8b-calibs-decam ./image-list-decam.txt\n",
    "qdo load dr8b-calibs-90prime ./image-list-90prime.txt\n",
    "qdo load dr8b-calibs-mosaic ./image-list-mosaic.txt\n",
    "```\n",
    "Next, copy the relevant scripts into the working directory:\n",
    "```bash\n",
    "cp $LEGACYPIPE_DIR/doc/dr8/dr8-env-shifter.sh ./\n",
    "cp $LEGACYPIPE_DIR/doc/dr8/dr8-zpts-shifter.sh ./\n",
    "```\n",
    "The script `dr8-env-shifter.sh` does not need to be modified, but in the `dr8-zpts-shifter.sh` be sure to **check that the `dr`, `LEGACY_SURVEY_DIR`, and `CODE_DIR` variables are correct and up to date**.\n",
    "\n",
    "Then, utilize various queues to get everything done.  For example, for `DECam` it's not crazy to request 256 MPI tasks with 8 cores per task (equivalent to 256/8=64 nodes on `cori`).  Using the `debug` and `regular` queue for 30 and 120 minutes, respectively, (and the burst buffer) would look like\n",
    "```bash\n",
    "QDO_BATCH_PROFILE=cori-shifter qdo launch dr8b-calibs-decam 256 --cores_per_worker 8 \\\n",
    "  --walltime=00:30:00 --batchqueue=debug --keep_env --script ./dr8-zpts-shifter.sh \\\n",
    "  --batchopts \"--image=docker:legacysurvey/legacypipe:latest --bbf=bb.conf\"\n",
    "\n",
    "QDO_BATCH_PROFILE=cori-shifter qdo launch dr8b-calibs-decam 256 --cores_per_worker 8 \\\n",
    "  --walltime=02:00:00 --batchqueue=regular --keep_env --script ./dr8-zpts-shifter.sh \\\n",
    "  --batchopts \"--image=docker:legacysurvey/legacypipe:latest --bbf=bb.conf\"\n",
    "```  \n",
    "\n",
    "The game, of course, is to balance throughput and wait time, although in general the debug queues work quite well, even on the DECam images (with ~60 CCDs each).\n",
    "\n",
    "Alternatively, one could use the shared queue with\n",
    "```bash\n",
    "QDO_BATCH_PROFILE=cori-shifter qdo launch dr8b-calibs-decam 1 --cores_per_worker 8 \\\n",
    "  --walltime=04:00:00 --batchqueue=shared --keep_env --script ./dr8-zpts-shifter.sh \\\n",
    "  --batchopts \"--image=docker:legacysurvey/legacypipe:latest -a 0-99 --bbf=bb.conf\"\n",
    "```\n",
    "which may also work well in production.\n",
    "\n",
    "Note that for the `90prime` and `mosaic` cameras (which only have 4 CCDs) a more typical request would be \n",
    "```bash\n",
    "QDO_BATCH_PROFILE=cori-shifter qdo launch dr8b-calibs-mosaic 512 --cores_per_worker 4 \\\n",
    "  --walltime=00:30:00 --batchqueue=debug --keep_env --script ./dr8-zpts-shifter.sh \\\n",
    "  --batchopts \"--image=docker:legacysurvey/legacypipe:latest --bbf=bb.conf\"\n",
    "```\n",
    "\n",
    "For the record, files will be written out with the following directory structure (all relative to `$DW_PERSISTENT_STRIPED_DR8/dr8b`):\n",
    "```\n",
    "zpts\n",
    "  90prime\n",
    "    CP*/[image-file]-annotated.fits\n",
    "    CP*/[image-file]-photom.fits\n",
    "    CP*/[image-file]-survey.fits\n",
    "  decam\n",
    "    CP*/[image-file]-annotated.fits\n",
    "    CP*/[image-file]-photom.fits\n",
    "    CP*/[image-file]-survey.fits\n",
    "  mosaic\n",
    "    CP*/[image-file]-annotated.fits\n",
    "    CP*/[image-file]-photom.fits\n",
    "    CP*/[image-file]-survey.fits\n",
    "calib\n",
    "  90prime\n",
    "    psfex\n",
    "    psfex-merged/?????/90prime-????????.fits\n",
    "    se\n",
    "    splinesky\n",
    "    splinesky-merged/?????/90prime-????????.fits\n",
    "  decam\n",
    "    psfex\n",
    "    psfex-merged/?????/decam-????????.fits\n",
    "    se\n",
    "    splinesky\n",
    "    splinesky-merged/?????/decam-????????.fits\n",
    "  mosaic\n",
    "    psfex\n",
    "    psfex-merged/?????/mosaic-????????.fits\n",
    "    se\n",
    "    splinesky\n",
    "    splinesky-merged/?????/mosaic-????????.fits\n",
    "```\n",
    "\n",
    "The only files we care about, however, are all the files in the `zpts`, `splinesky-merged`, and `psfex-merged` directories; the files in the SExtractor (se), psfex, and splinesky directories are intermittent and will be deleted in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Some useful qdo commands.\n",
    "\n",
    "The following `qdo` commands may be useful:\n",
    "```bash\n",
    "qdo list \n",
    "qdo status dr8b-calibs-decam                  # check on current status\n",
    "qdo retry dr8b-calibs-decam                   # re-load failed jobs (presumably after debugging the code)\n",
    "qdo recover dr8b-calibs-decam --dead          # re-load jobs that hung because the queue timed out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. Rsync everything to *project*.\n",
    "\n",
    "Once all calibrations are done the necessary outputs should be copied to `project`:\n",
    "\n",
    "```bash\n",
    "cd $DW_PERSISTENT_SCRATCH/dr8b\n",
    "rsync -auv zpts $LEGACY_SURVEY_DIR >> rsync-zpts.log 2>&1 &\n",
    "rsync -auvR calib/*/*-merged $LEGACY_SURVEY_DIR >> rsync-calib.log 2>&1 &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4. Build the merged *survey-ccds* and *annotated-ccds* files (and their KD-tree cousins).\n",
    "* **ToDo**: Document a slurm script for doing this.\n",
    "* **ToDo**: Before merging, validate the input image list and output catalogs.  For `DR8b` there's a small script `misc/validate-calibs.py`, but it won't scale well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to merge all the individual zeropoint files to generate the all-powerful *survey-ccds* and *annotated-ccds* files, which we can accomplish with `dr8-merge-zpts.sh`:\n",
    "```bash\n",
    "./$LEGACYPIPE_DIR/doc/dr8/dr8-merge-zpts.sh\n",
    "```\n",
    "This script builds a simple ASCII file list of the individual zeropoint tables (ignoring files with the \"debug\" suffix) and passes them to `legacyzpts/legacy_zeropoints_merge.py` and, subsequently, `legacypipe/create_kdtrees.py`, to create the following files:\n",
    "```bash\n",
    "annotated-ccds-dr8b-decam-nocuts.fits\n",
    "annotated-ccds-dr8b-90prime-mosaic-nocuts.fits  \n",
    "annotated-ccds-dr8b-decam-nocuts.kd.fits\n",
    "annotated-ccds-dr8b-90prime-mosaic-nocuts.kd.fits  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. Update ccd_cuts and apply depth cuts (optional).\n",
    "* **ToDo**: Document this step (see notebook/notes by Adam and Dustin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B6. Generate QA of the input CCDs tables.\n",
    "* **ToDo**: Generate a standard set of plots showing the coverage of the CCDs files, scatter in zeropoints, comparisons to previous DRs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Run the *legacypipe* pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1. Set up the *runbrick-decam* and *runbrick-90prime-mosaic* directories.\n",
    "\n",
    "The pipeline has to be run separately for the DECam and 90Prime+Mosaic datasets, so we need to create and set up different dedicated directories. For example, for DECam, do:\n",
    "```bash\n",
    "mkdir -p runbrick-decam\n",
    "cd runbrick-decam\n",
    "ln -s ../bb.conf bb.conf\n",
    "ln -s ../calib calib\n",
    "ln -s ../code code\n",
    "ln -s ../images images\n",
    "ln -s ../survey-bricks.fits.gz survey-bricks.fits.gz\n",
    "ln -s ../survey-ccds-dr8b-decam-nocuts.kd.fits survey-ccds-dr8b-decam-nocuts.kd.fits\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2. Set up the *shifter* script.\n",
    "\n",
    "Next, we need two shell scripts which set up `runbrick` specifically for this input directory and camera:\n",
    "```bash\n",
    "cp $LEGACYPIPE_DIR/doc/dr8/dr8-env-shifter.sh ./\n",
    "cp $LEGACYPIPE_DIR/doc/dr8/dr8-runbrick-shifter-decam.sh ./\n",
    "```\n",
    "However, be sure to **verify that the `dr`, `camera`, `release`, `LEGACY_SURVEY_DIR`, and `CODE_DIR` environment variables are all correct and up to date**.\n",
    "\n",
    "And that's it!  Setting up the `runbrick-90prime-mosaic` directory is analogous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3. Load the set of qdo tasks (lists of bricks).\n",
    "\n",
    "* **ToDo**: These instructions aren't quite right because the various regions use different `survey-ccd` files.\n",
    "\n",
    "With our I/O directory set up and our `survey-ccds` table in hand, we are ready to run `legacypipe`.  First, create a list of bricks to load into `qdo` using `legacypipe/queue-calibs.py`.  In `dr8a` and `dr8b` we focused on a set of [test regions](https://desi.lbl.gov/trac/wiki/DecamLegacy/DR8testregions).  The unique set of bricks in these regions were separately determined by Adam Myers, but can be rederived with, e.g.,\n",
    "```bash\n",
    "cd /global/project/projectdirs/cosmo/work/legacysurvey/dr8b/runbrick-decam\n",
    "source dr8-env-decam.sh\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-s82 > bricks-test-s82\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-hsc-sgc > bricks-test-hsc-sgc\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-hsc-ngc > bricks-test-hsc-ngc\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-edr > bricks-test-edr\n",
    "```\n",
    "To keep the top-level directory tidy, these files should be copied to a new directory, `dr8b/brick-lists`. \n",
    "\n",
    "Next, create a `qdo` queue for each test region (so that completing a particular region can be prioritized) with\n",
    "```bash\n",
    "qdo load dr8b-test-s82-decam ./bricks-test-s82\n",
    "qdo load dr8b-test-hsc-sgc-decam ./bricks-test-hsc-sgc\n",
    "qdo load dr8b-test-hsc-ngc-decam ./bricks-test-hsc-ngc\n",
    "qdo load dr8b-test-edr-decam ./bricks-test-edr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3. Launch *runbrick*.\n",
    "* **ToDo**: Add more info here.\n",
    "\n",
    "```bash\n",
    "QDO_BATCH_PROFILE=cori-shifter qdo launch dr8b-test-hsc-ngc-decam 256 --cores_per_worker 8 \\\n",
    "  --walltime=00:30:00 --batchqueue=debug --keep_env --script ./dr8-runbrick-shifter-decam.sh \\\n",
    "  --batchopts \"--image=docker:legacysurvey/legacypipe:latest --bbf=bb.conf\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C5. Rsync the output catalogs back to *project*.\n",
    "* **ToDo**: Add more info here.\n",
    "\n",
    "```bash\n",
    "cd $DW_PERSISTENT_SCRATCH/dr8b/runbrick-decam\n",
    "rsync -auv tractor* $LEGACY_SURVEY_DIR >> rsync-tractor.log 2>&1 &\n",
    "rsync -auv coadd $LEGACY_SURVEY_DIR >> rsync-coadd.log 2>&1 &\n",
    "rsync -auv metrics $LEGACY_SURVEY_DIR >> rsync-metrics.log 2>&1 &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Update the viewer\n",
    "* **ToDo**: Add more info here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Edit `/global/project/projectdirs/cosmo/webapp/viewer-dev/load-layer.py` and then run it (takes a long time...)\n",
    "* Then “touch wsgi.py” and then reload legacysurvey.org."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
