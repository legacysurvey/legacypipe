{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DR8b\n",
    "\n",
    "The goal of this notebook is to document how we ran [DR8b](https://desi.lbl.gov/trac/wiki/DecamLegacy/DR8#Testregions), including calibration files, with the updated data model and using the burst buffer on Cori.\n",
    "\n",
    "John Moustakas  \n",
    "Siena College  \n",
    "2019 March 10\n",
    "\n",
    "Many thanks to Dustin Lang, Adam Myers, Eddie Schlafly, David Schlegel, Martin Landriau, and Stephen Bailey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1. Define $LEGACY_SURVEY_DIR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, choose a new, empty top-level directory on `project` and create it:\n",
    "```bash\n",
    "export LEGACY_SURVEY_DIR=/global/project/projectdirs/cosmo/work/legacysurvey/dr8b\n",
    "mkdir -p $LEGACY_SURVEY_DIR\n",
    "cd $LEGACY_SURVEY_DIR\n",
    "```\n",
    "Note: the same `$LEGACY_SURVEY_DIR` environment variable will need to be defined within the scripts below so that they are self-contained.\n",
    "\n",
    "**Hereafter I will assume that all scripts are launched from the $LEGACY_SURVEY_DIR directory.**\n",
    "\n",
    "Next, create soft links to the CP-reduced imaging data and the WISE background models:\n",
    "```bash\n",
    "mkdir -p images calib/wise\n",
    "ln -s /global/project/projectdirs/cosmo/staging/90prime images/90prime\n",
    "ln -s /global/project/projectdirs/cosmo/staging/mosaic images/mosaic\n",
    "ln -s /global/project/projectdirs/cosmo/staging/decam images/decam\n",
    "ln -s /project/projectdirs/cosmo/work/wise/unwise_catalog/dr1/mod calib/wise/modelsky\n",
    "```\n",
    "\n",
    "And finally grab a copy of the `survey-bricks` file, which we will need below:\n",
    "```bash\n",
    "cp /global/project/projectdirs/cosmo/work/legacysurvey/dr7/survey-bricks.fits.gz .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Access (or create) the burst buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, Dustin Lang created a 40TB burst-buffer reservation called \"DR8\".  You can think of this as a mounted external drive, where large files can be written and read without the significant overhead associated with `$SCRATCH`, although eventually the results will be copied onto `project`, as described below.\n",
    "\n",
    "To access this file system for the first time you have to create a configuration file (just once).\n",
    "```bash\n",
    "echo \"#DW persistentdw name=DR8\" > bb.conf\n",
    "```\n",
    "\n",
    "The files in the burst buffer can be accessed *only* from an interactive Cori node.  Let's do this (just once) and make a dedicated subdirectory to keep our outputs tidy:\n",
    "```bash\n",
    "salloc -N 1 -C haswell -q interactive -t 00:10:00 --bbf=bb.conf\n",
    "mkdir -p $DW_PERSISTENT_STRIPED_DR8/dr8b\n",
    "```\n",
    "Note that the `$DW_PERSISTENT_STRIPED_DR8` environment variable must be used *always*, as every user will have a different absolute path.\n",
    "\n",
    "For the record, a new reservation can be made (if necessary) by submitting the following SLURM script to the queue:\n",
    "\n",
    "```bash\n",
    "#! /bin/bash\n",
    "#SBATCH -q debug\n",
    "#SBATCH -N 1\n",
    "#SBATCH -C haswell\n",
    "#SBATCH -t 00:05:00\n",
    "#BB create_persistent name=BBNAME capacity=50000GB access_mode=striped type=scratch\n",
    "```\n",
    "where `BBNAME` is the desired name of the reservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Set up software dependencies.\n",
    "**ToDo**: Add Docker instructions (link to Adam's NB).  \n",
    "**ToDo**: Add instructions for compiling tractor and astrometry.net, if needed (separate notebook).  \n",
    "**Note**: In DR8b we had to rely on a local installations of `qdo` and `tractor` and `astrometry.net` (on edison), but here we document the ideal setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code dependencies are in the `desiconda` imaging stack (like [tractor](https://github.com/dstndstn/tractor) and [astrometry.net](https://github.com/dstndstn/astrometry.net)), which we will source in our setup script, below, but we usually depend on a recent (hopefully tagged) version of [legacyzpts](https://github.com/legacysurvey/legacyzpts) and [legacypipe](https://github.com/legacysurvey/legacypipe).\n",
    "\n",
    "```bash\n",
    "cd $LEGACY_SURVEY_DIR\n",
    "mkdir -p code ; cd code\n",
    "git clone git@github.com:legacysurvey/legacyzpts.git ; cd legacyzpts\n",
    "git checkout tags/dr8.0 ; cd ..\n",
    "git clone git@github.com:legacysurvey/legacypipe.git\n",
    "cd ..\n",
    "```\n",
    "Next, make a local copy (for convenience of editing, temporarily changing paths, etc.) of the bash script we use to set up all the necessary dependencies and myriad environment variables:\n",
    "```bash\n",
    "cp code/legacypipe/doc/dr8/dr8-env.sh .\n",
    "```\n",
    "Be sure to update this script with the appropriate `$LEGACY_SURVEY_DIR` path, and you will also need to add the following lines (and get the appropriate database password) in order to complete the `qdo` setup (for the *desiconda* user these lines are in the `.bashrc.ext` file):\n",
    "```bash\n",
    "export QDO_BACKEND=postgres\n",
    "export QDO_BATCH_PROFILE=cori\n",
    "export QDO_DB_HOST=nerscdb03.nersc.gov\n",
    "export QDO_DB_NAME=desirun\n",
    "export QDO_DB_USER=desirun_admin\n",
    "export QDO_DB_PASS=ask_someone_on_the_imaging_team\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A4. Create the input image lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DR8 Eddie Schlafly and David Schlegel inspected all the `DECam`, `90prime`, and `mosaic` imaging data on-disk and created three FITS files which should be used to define the input data:\n",
    "* dr8-ondisk-decam.fits\n",
    "* dr8-ondisk-90prime.fits\n",
    "* dr8-ondisk-mosaic.fits\n",
    "\n",
    "We use these tables (cutting on `QKEEP==True`) to create our input image lists.  To keep everything tidy, create a new `$LEGACY_SURVEY_DIR/image-lists` subdirectory, copy the `dr8-ondisk-*.fits` files there, source the `dr8-env.sh` file, and then run the following snippet of code in an `ipython` session.\n",
    "```python\n",
    "import os\n",
    "import fitsio\n",
    "for camera in ('decam', 'mosaic', '90prime'):\n",
    "    data = fitsio.read('dr8-ondisk-{}.fits'.format(camera), upper=True)\n",
    "    with open('image-list-{}.txt'.format(camera), 'w') as flist:\n",
    "        for imfile in data[data['QKEEP']]['FILENAME']:\n",
    "            flist.write('{}\\n'.format(os.path.join(camera, imfile.decode('utf-8').strip())))\n",
    "```\n",
    "The resulting output files are:\n",
    "* image-list-decam.txt (121123 images in DR8, 5515 in DR8b)\n",
    "* image-list-90prime.txt (34206 images in DR8, 1073 in DR8b)\n",
    "* image-list-mosaic.txt (61049 images in DR8, 1374 in DR8b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Generate the calibration files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Load and launch qdo tasks (lists of images).\n",
    "\n",
    "We use `qdo` to manage the myriad of tasks (one task = one image), and the shell script `dr8-zpts.sh` to produce the calibration files we need.  First, load the tasks into the database with\n",
    "```bash\n",
    "qdo load dr8b-calibs-decam ./image-list-decam.txt\n",
    "qdo load dr8b-calibs-90prime ./image-list-90prime.txt\n",
    "qdo load dr8b-calibs-mosaic ./image-list-mosaic.txt\n",
    "```\n",
    "Finally, utilize various queues to get everything done.  For example, for `DECam` it's not crazy to request 256 MPI tasks with 8 cores per task (equivalent to 256/8=64 nodes on `cori`).  Using the `debug` and `regular` queue for 30 and 180 minutes, respectively, (and the burst buffer) would look like\n",
    "```bash\n",
    "qdo launch dr8b-calibs-decam 256 --cores_per_worker 8 --walltime=00:30:00 --script $LEGACYPIPE_DIR/doc/dr8/dr8-zpts.sh \\\n",
    "  --batchqueue debug --keep_env --batchopts \"--bbf=bb.conf\"\n",
    "qdo launch dr8b-calibs-decam 256 --cores_per_worker 8 --walltime=03:00:00 --script $LEGACYPIPE_DIR/doc/dr8/dr8-zpts.sh \\\n",
    "  --batchqueue regular --keep_env --batchopts \"--bbf=bb.conf\"\n",
    "```\n",
    "The game, of course, is to balance throughput and wait time, although in general the debug queues work quite well, even on the DECam images (with ~60 CCDs each).\n",
    "\n",
    "Alternatively, one could use the shared queue with\n",
    "```bash\n",
    "qdo launch dr8b-calibs-decam 1 --cores_per_worker 8 --walltime=04:00:00 --script $LEGACYPIPE_DIR/doc/dr8/dr8-zpts.sh \\\n",
    "  --batchqueue shared --keep_env --batchopts \"--bbf=bb.conf -a 0-99\"\n",
    "```\n",
    "which may also work well in production.\n",
    "\n",
    "Note that for the `90prime` and `mosaic` cameras (which only have 4 CCDs) a more typical request would be \n",
    "```bash\n",
    "qdo launch dr8b-calibs-mosaic 512 --cores_per_worker 4 --walltime=00:30:00 --script $LEGACYPIPE_DIR/doc/dr8/dr8-zpts.sh \\\n",
    "  --batchqueue debug --keep_env --batchopts \"--bbf=bb.conf\"\n",
    "```\n",
    "\n",
    "For the record, `dr8-zpts.sh` will write files out with the following directory structure (all relative to `$DW_PERSISTENT_STRIPED_DR8/dr8b`):\n",
    "```\n",
    "zpts\n",
    "  90prime\n",
    "    CP*/[image-file]-annotated.fits\n",
    "    CP*/[image-file]-photom.fits\n",
    "    CP*/[image-file]-survey.fits\n",
    "  decam\n",
    "    CP*/[image-file]-annotated.fits\n",
    "    CP*/[image-file]-photom.fits\n",
    "    CP*/[image-file]-survey.fits\n",
    "  mosaic\n",
    "    CP*/[image-file]-annotated.fits\n",
    "    CP*/[image-file]-photom.fits\n",
    "    CP*/[image-file]-survey.fits\n",
    "calib\n",
    "  90prime\n",
    "    psfex\n",
    "    psfex-merged/?????/90prime-????????.fits\n",
    "    se\n",
    "    splinesky\n",
    "    splinesky-merged/?????/90prime-????????.fits\n",
    "  decam\n",
    "    psfex\n",
    "    psfex-merged/?????/decam-????????.fits\n",
    "    se\n",
    "    splinesky\n",
    "    splinesky-merged/?????/decam-????????.fits\n",
    "  mosaic\n",
    "    psfex\n",
    "    psfex-merged/?????/mosaic-????????.fits\n",
    "    se\n",
    "    splinesky\n",
    "    splinesky-merged/?????/mosaic-????????.fits\n",
    "```\n",
    "\n",
    "The only files we care about, however, are all the files in the `zpts`, `splinesky-merged`, and `psfex-merged` directories; the files in the SExtractor (se), psfex, and splinesky directories are intermittent and will be deleted in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Some useful qdo commands.\n",
    "\n",
    "The following `qdo` commands may be useful:\n",
    "```bash\n",
    "qdo list \n",
    "qdo do dr8b-calibs-decam --script dr8-zpts.sh # run the script interactively\n",
    "qdo status dr8b-calibs-decam                  # check on current status\n",
    "qdo retry dr8b-calibs-decam                   # re-load failed jobs (presumably after debugging the code)\n",
    "qdo recover dr8b-calibs-decam --dead          # re-load jobs that hung because the queue timed out\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. Rsync everything to *project*.\n",
    "\n",
    "Once all calibrations are done the necessary outputs should be copied to `project`:\n",
    "\n",
    "```bash\n",
    "cd $DW_PERSISTENT_SCRATCH/dr8b\n",
    "rsync -auv zpts $LEGACY_SURVEY_DIR >> rsync-zpts.log 2>&1 &\n",
    "rsync -auvR calib/*/*-merged $LEGACY_SURVEY_DIR >> rsync-calib.log 2>&1 &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4. Build the merged *survey-ccds* and *annotated-ccds* files (and their KD-tree cousins).\n",
    "* **ToDo**: Document a slurm script for doing this.\n",
    "* **ToDo**: Before merging, validate the input image list and output catalogs.  For `DR8b` there's a small script `misc/validate-calibs.py`, but it won't scale well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to merge all the individual zeropoint files to generate the all-powerful *survey-ccds* and *annotated-ccds* files, which we can accomplish with `dr8-merge-zpts.sh`:\n",
    "```bash\n",
    "./$LEGACYPIPE_DIR/doc/dr8/dr8-merge-zpts.sh\n",
    "```\n",
    "This script builds a simple ASCII file list of the individual zeropoint tables (ignoring files with the \"debug\" suffix) and passes them to `legacyzpts/legacy_zeropoints_merge.py` and, subsequently, `legacypipe/create_kdtrees.py`, to create the following files:\n",
    "```bash\n",
    "annotated-ccds-dr8b-decam-nocuts.fits\n",
    "annotated-ccds-dr8b-90prime-mosaic-nocuts.fits  \n",
    "annotated-ccds-dr8b-decam-nocuts.kd.fits\n",
    "annotated-ccds-dr8b-90prime-mosaic-nocuts.kd.fits  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B5. Update ccd_cuts and apply depth cuts (optional).\n",
    "* **ToDo**: Document this step (see notebook/notes by Adam and Dustin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B6. Generate QA of the input CCDs tables.\n",
    "* **ToDo**: Generate a standard set of plots showing the coverage of the CCDs files, scatter in zeropoints, comparisons to previous DRs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Run the *legacypipe* pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1. Set up the *runbrick-decam* and *runbrick-90prime-mosaic* directories.\n",
    "\n",
    "The pipeline has to be run separately for the DECam and 90Prime+Mosaic datasets, so we need to create and set up different dedicated directories. For example, for DECam, do:\n",
    "```bash\n",
    "mkdir -p runbrick-decam\n",
    "cd runbrick-decam\n",
    "ln -s ../bb.conf bb.conf\n",
    "ln -s ../calib calib\n",
    "ln -s ../code code\n",
    "ln -s ../images images\n",
    "ln -s ../survey-bricks.fits.gz survey-bricks.fits.gz\n",
    "ln -s ../survey-ccds-dr8b-decam-nocuts.kd.fits survey-ccds-dr8b-decam-nocuts.kd.fits\n",
    "```\n",
    "\n",
    "Next, we need a shell script which sets up `runbrick` specifically for this input directory.  Fortunately, all we have to do is copy our generic shell script which sets up our code and dependencies\n",
    "```bash\n",
    "cp $LEGACYPIPE_DIR/doc/dr8/dr8-env.sh ./dr8-env-decam.sh\n",
    "```\n",
    "but then change the `LEGACY_SURVEY_DIR` environment variable to\n",
    "```bash\n",
    "export =/global/project/projectdirs/cosmo/work/legacysurvey/dr8b/runbrick-decam\n",
    "```\n",
    "And that's it!  Setting up the `runbrick-90prime-mosaic` directory is analogous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2. Load the set of qdo tasks (lists of bricks).\n",
    "\n",
    "* **ToDo**: These instructions aren't quite right because the various regions use different `survey-ccd` files.\n",
    "\n",
    "With our I/O directory set up and our `survey-ccds` table in hand, we are ready to run `legacypipe`.  First, create a list of bricks to load into `qdo` using `legacypipe/queue-calibs.py`.  In `DR8a` and `DR8b` we focused on a set of [test regions](https://desi.lbl.gov/trac/wiki/DecamLegacy/DR8testregions).  The unique set of bricks in these regions were separately determined by Adam Myers, but can be rederived with, e.g.,\n",
    "```bash\n",
    "cd /global/project/projectdirs/cosmo/work/legacysurvey/dr8b/runbrick-decam\n",
    "source dr8-env-decam.sh\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-s82 > bricks-test-s82\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-hsc-sgc > bricks-test-hsc-sgc\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-hsc-ngc > bricks-test-hsc-ngc\n",
    "python $LEGACYPIPE_DIR/py/legacypipe/queue-calibs.py --region dr8-test-edr > bricks-test-edr\n",
    "```\n",
    "To keep the top-level directory tidy, these files should be copied to a new directory, `dr8b/brick-lists`. \n",
    "\n",
    "Next, create a `qdo` queue for each test region (so that completing a particular region can be prioritized) with\n",
    "```bash\n",
    "qdo load dr8b-test-s82-decam ./bricks-test-s82\n",
    "qdo load dr8b-test-hsc-sgc-decam ./bricks-test-hsc-sgc\n",
    "qdo load dr8b-test-hsc-ngc-decam ./bricks-test-hsc-ngc\n",
    "qdo load dr8b-test-edr-decam ./bricks-test-edr\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4. Launch *runbrick*.\n",
    "* **ToDo**: Add more info here.\n",
    "\n",
    "```bash\n",
    "qdo launch dr8b-test-hsc-ngc-decam 256 --cores_per_worker 8 --walltime=00:30:00 \\\n",
    "  --script ./dr8-runbrick-decam.sh --batchqueue debug --keep_env --batchopts \"--bbf=bb.conf\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3. Rsync the output catalogs back to *project*.\n",
    "* **ToDo**: Add more info here.\n",
    "\n",
    "```bash\n",
    "cd $DW_PERSISTENT_SCRATCH/dr8b/runbrick-decam\n",
    "rsync -auv tractor* $LEGACY_SURVEY_DIR >> rsync-tractor.log 2>&1 &\n",
    "rsync -auv coadd $LEGACY_SURVEY_DIR >> rsync-coadd.log 2>&1 &\n",
    "rsync -auv metrics $LEGACY_SURVEY_DIR >> rsync-metrics.log 2>&1 &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Update the viewer\n",
    "* **ToDo**: Add more info here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Edit `/global/project/projectdirs/cosmo/webapp/viewer-dev/load-layer.py` and then run it (takes a long time...)\n",
    "* Then “touch wsgi.py” and then reload legacysurvey.org."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
